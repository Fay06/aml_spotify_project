{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv.gz\")\n",
    "test = pd.read_csv(\"data/test.csv.gz\")\n",
    "\n",
    "train = train.iloc[:, 1:]\n",
    "test = test.iloc[:, 1:]\n",
    "\n",
    "train[\"artists\"] = train[\"artists\"].str[1:-1].str.replace(\"'\", \"\").str.split(\",\")\n",
    "train[\"artist_ids\"] = train[\"artist_ids\"].str[1:-1].str.replace(\"'\", \"\").str.split(\",\")\n",
    "\n",
    "test[\"artists\"] = test[\"artists\"].str[1:-1].str.replace(\"'\", \"\").str.split(\",\")\n",
    "test[\"artist_ids\"] = test[\"artist_ids\"].str[1:-1].str.replace(\"'\", \"\").str.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"decade\"] - 1\n",
    "y_test = test[\"decade\"] - 1\n",
    "\n",
    "X_train = train.drop([\"year\", \"decade\"], axis=1)\n",
    "X_test = test.drop([\"year\", \"decade\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols = [\"explicit\", \"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_ms\", \"time_signature\", \"num_artists\"]\n",
    "X_train = X_train[continuous_cols + [\"primary_artist\"]]\n",
    "X_test = X_test[continuous_cols + [\"primary_artist\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "te = ce.TargetEncoder()\n",
    "te.fit(X_train[\"primary_artist\"], train[\"year\"])\n",
    "\n",
    "X_train[\"primary_artist\"] = te.transform(X_train[\"primary_artist\"])\n",
    "X_train[\"explicit\"] = X_train[\"explicit\"].astype(int)\n",
    "\n",
    "X_test[\"primary_artist\"] = te.transform(X_test[\"primary_artist\"])\n",
    "X_test[\"explicit\"] = X_test[\"explicit\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>num_artists</th>\n",
       "      <th>primary_artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.248</td>\n",
       "      <td>1</td>\n",
       "      <td>-17.622</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0594</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>102.034</td>\n",
       "      <td>254693</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007.032433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.187</td>\n",
       "      <td>9</td>\n",
       "      <td>-17.351</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.86800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>98.907</td>\n",
       "      <td>208507</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1978.529700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.483</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.52900</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>205.581</td>\n",
       "      <td>200293</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013.137622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.212</td>\n",
       "      <td>7</td>\n",
       "      <td>-17.780</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0949</td>\n",
       "      <td>0.84700</td>\n",
       "      <td>0.003370</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>81.949</td>\n",
       "      <td>640933</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2003.890173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.825</td>\n",
       "      <td>11</td>\n",
       "      <td>-10.767</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.00281</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.8990</td>\n",
       "      <td>167.625</td>\n",
       "      <td>200707</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1994.305755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771813</th>\n",
       "      <td>0</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.730</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.57700</td>\n",
       "      <td>0.439000</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.4660</td>\n",
       "      <td>169.963</td>\n",
       "      <td>156671</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016.246368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771814</th>\n",
       "      <td>0</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.074</td>\n",
       "      <td>2</td>\n",
       "      <td>-17.670</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.97600</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.0892</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>77.003</td>\n",
       "      <td>197667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013.794955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771815</th>\n",
       "      <td>0</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.231</td>\n",
       "      <td>9</td>\n",
       "      <td>-11.634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.83000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.2980</td>\n",
       "      <td>0.6050</td>\n",
       "      <td>125.227</td>\n",
       "      <td>144627</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008.709622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771816</th>\n",
       "      <td>0</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.219</td>\n",
       "      <td>11</td>\n",
       "      <td>-14.741</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>0.82800</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.4020</td>\n",
       "      <td>137.498</td>\n",
       "      <td>212693</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1997.927018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771817</th>\n",
       "      <td>0</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.444</td>\n",
       "      <td>11</td>\n",
       "      <td>-14.098</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.71000</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>105.019</td>\n",
       "      <td>271280</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010.928699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>771818 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        explicit  danceability  energy  key  loudness  mode  speechiness  \\\n",
       "0              0         0.434   0.248    1   -17.622     1       0.0594   \n",
       "1              0         0.585   0.187    9   -17.351     1       0.0428   \n",
       "2              0         0.442   0.421    0    -6.483     1       0.1980   \n",
       "3              0         0.338   0.212    7   -17.780     1       0.0949   \n",
       "4              0         0.511   0.825   11   -10.767     1       0.0350   \n",
       "...          ...           ...     ...  ...       ...   ...          ...   \n",
       "771813         0         0.735   0.380    0    -9.730     1       0.0365   \n",
       "771814         0         0.355   0.074    2   -17.670     1       0.0317   \n",
       "771815         0         0.757   0.231    9   -11.634     1       0.0361   \n",
       "771816         0         0.439   0.219   11   -14.741     1       0.0337   \n",
       "771817         0         0.701   0.444   11   -14.098     1       0.0343   \n",
       "\n",
       "        acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "0            0.99400          0.804000    0.0968   0.2520  102.034   \n",
       "1            0.86800          0.000000    0.2010   0.5310   98.907   \n",
       "2            0.52900          0.000001    0.1130   0.9650  205.581   \n",
       "3            0.84700          0.003370    0.1670   0.1790   81.949   \n",
       "4            0.00281          0.033200    0.3590   0.8990  167.625   \n",
       "...              ...               ...       ...      ...      ...   \n",
       "771813       0.57700          0.439000    0.1500   0.4660  169.963   \n",
       "771814       0.97600          0.928000    0.0892   0.0605   77.003   \n",
       "771815       0.83000          0.000013    0.2980   0.6050  125.227   \n",
       "771816       0.82800          0.001170    0.1430   0.4020  137.498   \n",
       "771817       0.71000          0.878000    0.1040   0.4200  105.019   \n",
       "\n",
       "        duration_ms  time_signature  num_artists  primary_artist  \n",
       "0            254693             4.0            1     2007.032433  \n",
       "1            208507             4.0            1     1978.529700  \n",
       "2            200293             3.0            1     2013.137622  \n",
       "3            640933             4.0            3     2003.890173  \n",
       "4            200707             4.0            1     1994.305755  \n",
       "...             ...             ...          ...             ...  \n",
       "771813       156671             3.0            1     2016.246368  \n",
       "771814       197667             4.0            1     2013.794955  \n",
       "771815       144627             4.0            1     2008.709622  \n",
       "771816       212693             3.0            1     1997.927018  \n",
       "771817       271280             4.0            2     2010.928699  \n",
       "\n",
       "[771818 rows x 16 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_dev, X_val, y_dev, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((617454, 16), (154364, 16))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "                        layers.Dense(16, input_shape=(16,)), \n",
    "                        layers.Activation(\"relu\"), \n",
    "                        layers.Dense(12), \n",
    "                        layers.Activation(\"relu\"), \n",
    "                        layers.Dense(7), \n",
    "                        layers.Activation(\"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 12)                204       \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 12)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 7)                 91        \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 7)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 567\n",
      "Trainable params: 567\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4824/4824 [==============================] - 4s 806us/step - loss: 285.7591 - accuracy: 0.3168 - val_loss: 40.1222 - val_accuracy: 0.3594\n",
      "Epoch 2/20\n",
      "4824/4824 [==============================] - 3s 725us/step - loss: 121.3782 - accuracy: 0.3241 - val_loss: 116.0029 - val_accuracy: 0.4099\n",
      "Epoch 3/20\n",
      "4824/4824 [==============================] - 4s 774us/step - loss: 86.8671 - accuracy: 0.3205 - val_loss: 133.1831 - val_accuracy: 0.3648\n",
      "Epoch 4/20\n",
      "4824/4824 [==============================] - 3s 716us/step - loss: 48.5520 - accuracy: 0.3107 - val_loss: 1.9967 - val_accuracy: 0.0528\n",
      "Epoch 5/20\n",
      "4824/4824 [==============================] - 4s 756us/step - loss: 1.4470 - accuracy: 0.3788 - val_loss: 1.3420 - val_accuracy: 0.4095\n",
      "Epoch 6/20\n",
      "4824/4824 [==============================] - 4s 749us/step - loss: 1.3435 - accuracy: 0.4088 - val_loss: 1.3405 - val_accuracy: 0.4094\n",
      "Epoch 7/20\n",
      "4824/4824 [==============================] - 4s 823us/step - loss: 1.3429 - accuracy: 0.4087 - val_loss: 1.3403 - val_accuracy: 0.4092\n",
      "Epoch 8/20\n",
      "4824/4824 [==============================] - 4s 821us/step - loss: 1.3428 - accuracy: 0.4087 - val_loss: 1.3402 - val_accuracy: 0.4093\n",
      "Epoch 9/20\n",
      "4824/4824 [==============================] - 3s 719us/step - loss: 1.3428 - accuracy: 0.4087 - val_loss: 1.3402 - val_accuracy: 0.4093\n",
      "Epoch 10/20\n",
      "4824/4824 [==============================] - 4s 779us/step - loss: 1.3428 - accuracy: 0.4087 - val_loss: 1.3402 - val_accuracy: 0.4093\n",
      "Epoch 11/20\n",
      "4824/4824 [==============================] - 4s 739us/step - loss: 1.3428 - accuracy: 0.4087 - val_loss: 1.3402 - val_accuracy: 0.4093\n",
      "Epoch 12/20\n",
      "4824/4824 [==============================] - 4s 777us/step - loss: 1.3428 - accuracy: 0.4087 - val_loss: 1.3402 - val_accuracy: 0.4093\n",
      "Epoch 13/20\n",
      "4824/4824 [==============================] - 4s 751us/step - loss: 1.3428 - accuracy: 0.4087 - val_loss: 1.3402 - val_accuracy: 0.4093\n",
      "Epoch 14/20\n",
      "4824/4824 [==============================] - 4s 780us/step - loss: 1.3428 - accuracy: 0.4087 - val_loss: 1.3402 - val_accuracy: 0.4093\n",
      "Epoch 15/20\n",
      "4824/4824 [==============================] - 4s 788us/step - loss: 1.3428 - accuracy: 0.4087 - val_loss: 1.3402 - val_accuracy: 0.4093\n",
      "Epoch 16/20\n",
      "4824/4824 [==============================] - 4s 735us/step - loss: 1.3428 - accuracy: 0.4087 - val_loss: 1.3401 - val_accuracy: 0.4093\n",
      "Epoch 17/20\n",
      "4824/4824 [==============================] - 4s 799us/step - loss: 1.3428 - accuracy: 0.4087 - val_loss: 1.3402 - val_accuracy: 0.4093\n",
      "Epoch 18/20\n",
      "4824/4824 [==============================] - 4s 746us/step - loss: 1.3428 - accuracy: 0.4087 - val_loss: 1.3402 - val_accuracy: 0.4093\n",
      "Epoch 19/20\n",
      "4824/4824 [==============================] - 4s 783us/step - loss: 1.3428 - accuracy: 0.4087 - val_loss: 1.3402 - val_accuracy: 0.4093\n",
      "Epoch 20/20\n",
      "4824/4824 [==============================] - 4s 732us/step - loss: 1.3428 - accuracy: 0.4087 - val_loss: 1.3402 - val_accuracy: 0.4093\n"
     ]
    }
   ],
   "source": [
    "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history_callback = model.fit(X_dev, y_dev, validation_data=(X_val, y_val), batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19296/19296 [==============================] - 10s 514us/step\n",
      "6030/6030 [==============================] - 3s 462us/step\n",
      "dev accuracy:  0.40869117375545383\n",
      "test accuracy:  0.41113731180845275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dev_probs = model.predict(X_dev)\n",
    "test_probs = model.predict(X_test)\n",
    "\n",
    "print(\"dev accuracy: \", accuracy_score(dev_probs.argmax(axis=1), y_dev))\n",
    "print(\"test accuracy: \", accuracy_score(test_probs.argmax(axis=1), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9992779686633b1a0c917c3f6317d760e57d78a77247aa4b25ad344de6939a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
