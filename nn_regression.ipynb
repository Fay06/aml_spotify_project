{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv.gz\")\n",
    "test = pd.read_csv(\"data/test.csv.gz\")\n",
    "\n",
    "train = train.iloc[:, 1:]\n",
    "test = test.iloc[:, 1:]\n",
    "\n",
    "train[\"artists\"] = train[\"artists\"].str[1:-1].str.replace(\"'\", \"\").str.split(\",\")\n",
    "train[\"artist_ids\"] = train[\"artist_ids\"].str[1:-1].str.replace(\"'\", \"\").str.split(\",\")\n",
    "\n",
    "test[\"artists\"] = test[\"artists\"].str[1:-1].str.replace(\"'\", \"\").str.split(\",\")\n",
    "test[\"artist_ids\"] = test[\"artist_ids\"].str[1:-1].str.replace(\"'\", \"\").str.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"year\"]\n",
    "y_test = test[\"year\"]\n",
    "\n",
    "X_train = train.drop([\"year\", \"decade\"], axis=1)\n",
    "X_test = test.drop([\"year\", \"decade\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols = [\"explicit\", \"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_ms\", \"time_signature\", \"num_artists\"]\n",
    "X_train = X_train[continuous_cols + [\"primary_artist\"]]\n",
    "X_test = X_test[continuous_cols + [\"primary_artist\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "te = ce.TargetEncoder()\n",
    "te.fit(X_train[\"primary_artist\"], y_train)\n",
    "\n",
    "X_train[\"primary_artist\"] = te.transform(X_train[\"primary_artist\"])\n",
    "\n",
    "X_train[\"explicit\"] = X_train[\"explicit\"].astype(int)\n",
    "\n",
    "X_test[\"primary_artist\"] = te.transform(X_test[\"primary_artist\"])\n",
    "X_test[\"explicit\"] = X_test[\"explicit\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>num_artists</th>\n",
       "      <th>primary_artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.248</td>\n",
       "      <td>1</td>\n",
       "      <td>-17.622</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0594</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>102.034</td>\n",
       "      <td>254693</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007.032433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.187</td>\n",
       "      <td>9</td>\n",
       "      <td>-17.351</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.86800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>98.907</td>\n",
       "      <td>208507</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1978.529700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.483</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.52900</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>205.581</td>\n",
       "      <td>200293</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013.137622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.212</td>\n",
       "      <td>7</td>\n",
       "      <td>-17.780</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0949</td>\n",
       "      <td>0.84700</td>\n",
       "      <td>0.003370</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>81.949</td>\n",
       "      <td>640933</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2003.890173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.825</td>\n",
       "      <td>11</td>\n",
       "      <td>-10.767</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.00281</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.8990</td>\n",
       "      <td>167.625</td>\n",
       "      <td>200707</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1994.305755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771813</th>\n",
       "      <td>0</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.730</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.57700</td>\n",
       "      <td>0.439000</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.4660</td>\n",
       "      <td>169.963</td>\n",
       "      <td>156671</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016.246368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771814</th>\n",
       "      <td>0</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.074</td>\n",
       "      <td>2</td>\n",
       "      <td>-17.670</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.97600</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.0892</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>77.003</td>\n",
       "      <td>197667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013.794955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771815</th>\n",
       "      <td>0</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.231</td>\n",
       "      <td>9</td>\n",
       "      <td>-11.634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.83000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.2980</td>\n",
       "      <td>0.6050</td>\n",
       "      <td>125.227</td>\n",
       "      <td>144627</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008.709622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771816</th>\n",
       "      <td>0</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.219</td>\n",
       "      <td>11</td>\n",
       "      <td>-14.741</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>0.82800</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.4020</td>\n",
       "      <td>137.498</td>\n",
       "      <td>212693</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1997.927018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771817</th>\n",
       "      <td>0</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.444</td>\n",
       "      <td>11</td>\n",
       "      <td>-14.098</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.71000</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>105.019</td>\n",
       "      <td>271280</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010.928699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>771818 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        explicit  danceability  energy  key  loudness  mode  speechiness  \\\n",
       "0              0         0.434   0.248    1   -17.622     1       0.0594   \n",
       "1              0         0.585   0.187    9   -17.351     1       0.0428   \n",
       "2              0         0.442   0.421    0    -6.483     1       0.1980   \n",
       "3              0         0.338   0.212    7   -17.780     1       0.0949   \n",
       "4              0         0.511   0.825   11   -10.767     1       0.0350   \n",
       "...          ...           ...     ...  ...       ...   ...          ...   \n",
       "771813         0         0.735   0.380    0    -9.730     1       0.0365   \n",
       "771814         0         0.355   0.074    2   -17.670     1       0.0317   \n",
       "771815         0         0.757   0.231    9   -11.634     1       0.0361   \n",
       "771816         0         0.439   0.219   11   -14.741     1       0.0337   \n",
       "771817         0         0.701   0.444   11   -14.098     1       0.0343   \n",
       "\n",
       "        acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "0            0.99400          0.804000    0.0968   0.2520  102.034   \n",
       "1            0.86800          0.000000    0.2010   0.5310   98.907   \n",
       "2            0.52900          0.000001    0.1130   0.9650  205.581   \n",
       "3            0.84700          0.003370    0.1670   0.1790   81.949   \n",
       "4            0.00281          0.033200    0.3590   0.8990  167.625   \n",
       "...              ...               ...       ...      ...      ...   \n",
       "771813       0.57700          0.439000    0.1500   0.4660  169.963   \n",
       "771814       0.97600          0.928000    0.0892   0.0605   77.003   \n",
       "771815       0.83000          0.000013    0.2980   0.6050  125.227   \n",
       "771816       0.82800          0.001170    0.1430   0.4020  137.498   \n",
       "771817       0.71000          0.878000    0.1040   0.4200  105.019   \n",
       "\n",
       "        duration_ms  time_signature  num_artists  primary_artist  \n",
       "0            254693             4.0            1     2007.032433  \n",
       "1            208507             4.0            1     1978.529700  \n",
       "2            200293             3.0            1     2013.137622  \n",
       "3            640933             4.0            3     2003.890173  \n",
       "4            200707             4.0            1     1994.305755  \n",
       "...             ...             ...          ...             ...  \n",
       "771813       156671             3.0            1     2016.246368  \n",
       "771814       197667             4.0            1     2013.794955  \n",
       "771815       144627             4.0            1     2008.709622  \n",
       "771816       212693             3.0            1     1997.927018  \n",
       "771817       271280             4.0            2     2010.928699  \n",
       "\n",
       "[771818 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_dev, X_val, y_dev, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((617454, 16), (154364, 16))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970,\n",
       "       1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981,\n",
       "       1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992,\n",
       "       1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003,\n",
       "       2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014,\n",
       "       2015, 2016, 2017, 2018, 2019, 2020], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "                        layers.Dense(16, input_shape=(16,)), \n",
    "                        layers.Activation(\"relu\"), \n",
    "                        layers.Dense(16), \n",
    "                        layers.Activation(\"relu\"), \n",
    "                        layers.Dense(8), \n",
    "                        layers.Activation(\"relu\"), \n",
    "                        layers.Dense(4), \n",
    "                        layers.Activation(\"relu\"),\n",
    "                        layers.Dense(4), \n",
    "                        layers.Activation(\"relu\"), \n",
    "                        layers.Dense(1), \n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 16)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 741\n",
      "Trainable params: 741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2006\n",
       "1         2020\n",
       "2         2007\n",
       "3         2015\n",
       "4         2016\n",
       "          ... \n",
       "192950    2005\n",
       "192951    1993\n",
       "192952    2004\n",
       "192953    2009\n",
       "192954    2006\n",
       "Name: year, Length: 192955, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "655031    2012.0\n",
       "82364     2000.0\n",
       "547361    2019.0\n",
       "444452    2012.0\n",
       "245712    2013.0\n",
       "           ...  \n",
       "90474     2007.0\n",
       "657841    1995.0\n",
       "298959    2005.0\n",
       "104736    2003.0\n",
       "387032    2008.0\n",
       "Name: year, Length: 617454, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev.astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2412/2412 [==============================] - 3s 1ms/step - loss: 272.4179 - mean_squared_error: 272.4179 - val_loss: 201.5206 - val_mean_squared_error: 201.5206\n",
      "Epoch 2/50\n",
      "2412/2412 [==============================] - 2s 850us/step - loss: 209.9028 - mean_squared_error: 209.9028 - val_loss: 52.3254 - val_mean_squared_error: 52.3254\n",
      "Epoch 3/50\n",
      "2412/2412 [==============================] - 2s 1ms/step - loss: 220.7143 - mean_squared_error: 220.7143 - val_loss: 97.7414 - val_mean_squared_error: 97.7414\n",
      "Epoch 4/50\n",
      "2412/2412 [==============================] - 3s 1ms/step - loss: 260.1540 - mean_squared_error: 260.1540 - val_loss: 2795.7910 - val_mean_squared_error: 2795.7910\n",
      "Epoch 5/50\n",
      "2412/2412 [==============================] - 2s 946us/step - loss: 271.4757 - mean_squared_error: 271.4757 - val_loss: 45.0759 - val_mean_squared_error: 45.0759\n",
      "Epoch 6/50\n",
      "2412/2412 [==============================] - 2s 1ms/step - loss: 178.6757 - mean_squared_error: 178.6757 - val_loss: 140.8644 - val_mean_squared_error: 140.8644\n",
      "Epoch 7/50\n",
      "2412/2412 [==============================] - 2s 961us/step - loss: 205.9759 - mean_squared_error: 205.9759 - val_loss: 88.9059 - val_mean_squared_error: 88.9059\n",
      "Epoch 8/50\n",
      "2412/2412 [==============================] - 2s 1ms/step - loss: 416.9074 - mean_squared_error: 416.9074 - val_loss: 1734.4274 - val_mean_squared_error: 1734.4274\n",
      "Epoch 9/50\n",
      "2412/2412 [==============================] - 3s 1ms/step - loss: 136.9261 - mean_squared_error: 136.9261 - val_loss: 74.5848 - val_mean_squared_error: 74.5848\n",
      "Epoch 10/50\n",
      "2412/2412 [==============================] - 2s 911us/step - loss: 264.1589 - mean_squared_error: 264.1589 - val_loss: 48.4243 - val_mean_squared_error: 48.4243\n",
      "Epoch 11/50\n",
      "2412/2412 [==============================] - 2s 993us/step - loss: 203.3457 - mean_squared_error: 203.3457 - val_loss: 44.3144 - val_mean_squared_error: 44.3144\n",
      "Epoch 12/50\n",
      "2412/2412 [==============================] - 2s 973us/step - loss: 229.0113 - mean_squared_error: 229.0113 - val_loss: 47.4528 - val_mean_squared_error: 47.4528\n",
      "Epoch 13/50\n",
      "2412/2412 [==============================] - 2s 872us/step - loss: 199.1397 - mean_squared_error: 199.1397 - val_loss: 55.5349 - val_mean_squared_error: 55.5349\n",
      "Epoch 14/50\n",
      "2412/2412 [==============================] - 2s 960us/step - loss: 182.8057 - mean_squared_error: 182.8057 - val_loss: 45.0324 - val_mean_squared_error: 45.0324\n",
      "Epoch 15/50\n",
      "2412/2412 [==============================] - 3s 1ms/step - loss: 223.5811 - mean_squared_error: 223.5811 - val_loss: 44.3684 - val_mean_squared_error: 44.3684\n",
      "Epoch 16/50\n",
      "2412/2412 [==============================] - 3s 1ms/step - loss: 238.3685 - mean_squared_error: 238.3685 - val_loss: 47.1900 - val_mean_squared_error: 47.1900\n",
      "Epoch 17/50\n",
      "2412/2412 [==============================] - 2s 966us/step - loss: 154.8546 - mean_squared_error: 154.8546 - val_loss: 66.4200 - val_mean_squared_error: 66.4200\n",
      "Epoch 18/50\n",
      "2412/2412 [==============================] - 2s 972us/step - loss: 142.8451 - mean_squared_error: 142.8451 - val_loss: 131.6202 - val_mean_squared_error: 131.6202\n",
      "Epoch 19/50\n",
      "2412/2412 [==============================] - 2s 864us/step - loss: 185.8355 - mean_squared_error: 185.8355 - val_loss: 45.9952 - val_mean_squared_error: 45.9952\n",
      "Epoch 20/50\n",
      "2412/2412 [==============================] - 2s 897us/step - loss: 186.1066 - mean_squared_error: 186.1066 - val_loss: 109.1657 - val_mean_squared_error: 109.1657\n",
      "Epoch 21/50\n",
      "2412/2412 [==============================] - 2s 938us/step - loss: 179.3591 - mean_squared_error: 179.3591 - val_loss: 161.7915 - val_mean_squared_error: 161.7915\n",
      "Epoch 22/50\n",
      "2412/2412 [==============================] - 2s 855us/step - loss: 235.8506 - mean_squared_error: 235.8506 - val_loss: 142.2207 - val_mean_squared_error: 142.2207\n",
      "Epoch 23/50\n",
      "2412/2412 [==============================] - 2s 860us/step - loss: 183.9996 - mean_squared_error: 183.9996 - val_loss: 43.9107 - val_mean_squared_error: 43.9107\n",
      "Epoch 24/50\n",
      "2412/2412 [==============================] - 2s 865us/step - loss: 193.8148 - mean_squared_error: 193.8148 - val_loss: 79.2550 - val_mean_squared_error: 79.2550\n",
      "Epoch 25/50\n",
      "2412/2412 [==============================] - 2s 862us/step - loss: 180.0160 - mean_squared_error: 180.0160 - val_loss: 44.3583 - val_mean_squared_error: 44.3583\n",
      "Epoch 26/50\n",
      "2412/2412 [==============================] - 2s 856us/step - loss: 123.6684 - mean_squared_error: 123.6684 - val_loss: 140.3462 - val_mean_squared_error: 140.3462\n",
      "Epoch 27/50\n",
      "2412/2412 [==============================] - 2s 980us/step - loss: 162.4656 - mean_squared_error: 162.4656 - val_loss: 122.5882 - val_mean_squared_error: 122.5882\n",
      "Epoch 28/50\n",
      "2412/2412 [==============================] - 3s 1ms/step - loss: 157.5957 - mean_squared_error: 157.5957 - val_loss: 60.4981 - val_mean_squared_error: 60.4981\n",
      "Epoch 29/50\n",
      "2412/2412 [==============================] - 2s 905us/step - loss: 159.1436 - mean_squared_error: 159.1436 - val_loss: 279.1839 - val_mean_squared_error: 279.1839\n",
      "Epoch 30/50\n",
      "2412/2412 [==============================] - 2s 896us/step - loss: 208.3458 - mean_squared_error: 208.3458 - val_loss: 51.5398 - val_mean_squared_error: 51.5398\n",
      "Epoch 31/50\n",
      "2412/2412 [==============================] - 2s 979us/step - loss: 170.9417 - mean_squared_error: 170.9417 - val_loss: 45.4853 - val_mean_squared_error: 45.4853\n",
      "Epoch 32/50\n",
      "2412/2412 [==============================] - 2s 919us/step - loss: 176.5103 - mean_squared_error: 176.5103 - val_loss: 52.2256 - val_mean_squared_error: 52.2256\n",
      "Epoch 33/50\n",
      "2412/2412 [==============================] - 2s 861us/step - loss: 259.2509 - mean_squared_error: 259.2509 - val_loss: 47.8666 - val_mean_squared_error: 47.8666\n",
      "Epoch 34/50\n",
      "2412/2412 [==============================] - 2s 1ms/step - loss: 93.7692 - mean_squared_error: 93.7692 - val_loss: 45.9139 - val_mean_squared_error: 45.9139\n",
      "Epoch 35/50\n",
      "2412/2412 [==============================] - 3s 1ms/step - loss: 129.1719 - mean_squared_error: 129.1719 - val_loss: 56.1272 - val_mean_squared_error: 56.1272\n",
      "Epoch 36/50\n",
      "2412/2412 [==============================] - 2s 967us/step - loss: 157.7907 - mean_squared_error: 157.7907 - val_loss: 63.0633 - val_mean_squared_error: 63.0633\n",
      "Epoch 37/50\n",
      "2412/2412 [==============================] - 2s 1ms/step - loss: 152.6692 - mean_squared_error: 152.6692 - val_loss: 68.3383 - val_mean_squared_error: 68.3383\n",
      "Epoch 38/50\n",
      "2412/2412 [==============================] - 3s 1ms/step - loss: 145.0365 - mean_squared_error: 145.0365 - val_loss: 72.0959 - val_mean_squared_error: 72.0959\n",
      "Epoch 39/50\n",
      "2412/2412 [==============================] - 2s 949us/step - loss: 127.7191 - mean_squared_error: 127.7191 - val_loss: 44.3394 - val_mean_squared_error: 44.3394\n",
      "Epoch 40/50\n",
      "2412/2412 [==============================] - 3s 1ms/step - loss: 155.2177 - mean_squared_error: 155.2177 - val_loss: 59.4624 - val_mean_squared_error: 59.4624\n",
      "Epoch 41/50\n",
      "2412/2412 [==============================] - 2s 980us/step - loss: 135.3937 - mean_squared_error: 135.3937 - val_loss: 71.9526 - val_mean_squared_error: 71.9526\n",
      "Epoch 42/50\n",
      "2412/2412 [==============================] - 2s 850us/step - loss: 136.4421 - mean_squared_error: 136.4421 - val_loss: 47.3310 - val_mean_squared_error: 47.3310\n",
      "Epoch 43/50\n",
      "2412/2412 [==============================] - 2s 915us/step - loss: 143.2620 - mean_squared_error: 143.2620 - val_loss: 848.9290 - val_mean_squared_error: 848.9290\n",
      "Epoch 44/50\n",
      "2412/2412 [==============================] - 2s 789us/step - loss: 148.2052 - mean_squared_error: 148.2052 - val_loss: 48.9109 - val_mean_squared_error: 48.9109\n",
      "Epoch 45/50\n",
      "2412/2412 [==============================] - 2s 828us/step - loss: 132.0824 - mean_squared_error: 132.0824 - val_loss: 55.1251 - val_mean_squared_error: 55.1251\n",
      "Epoch 46/50\n",
      "2412/2412 [==============================] - 2s 931us/step - loss: 184.1939 - mean_squared_error: 184.1939 - val_loss: 57.1213 - val_mean_squared_error: 57.1213\n",
      "Epoch 47/50\n",
      "2412/2412 [==============================] - 2s 830us/step - loss: 256.5938 - mean_squared_error: 256.5938 - val_loss: 43.8188 - val_mean_squared_error: 43.8188\n",
      "Epoch 48/50\n",
      "2412/2412 [==============================] - 2s 812us/step - loss: 109.0088 - mean_squared_error: 109.0088 - val_loss: 52.7520 - val_mean_squared_error: 52.7520\n",
      "Epoch 49/50\n",
      "2412/2412 [==============================] - 2s 876us/step - loss: 121.5388 - mean_squared_error: 121.5388 - val_loss: 84.0177 - val_mean_squared_error: 84.0177\n",
      "Epoch 50/50\n",
      "2412/2412 [==============================] - 2s 888us/step - loss: 267.6304 - mean_squared_error: 267.6304 - val_loss: 44.5418 - val_mean_squared_error: 44.5418\n"
     ]
    }
   ],
   "source": [
    "model.compile(\"adam\", loss=\"mean_squared_error\", metrics=[\"mean_squared_error\"])\n",
    "history_callback = model.fit(X_dev, y_dev, validation_data=(X_val, y_val), batch_size=256, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19296/19296 [==============================] - 10s 500us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "dev_preds = model.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10930729915453119"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(dev_preds, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x20f0542ed60>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(dev_preds, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2412/2412 [==============================] - 3s 936us/step - loss: 3.6496e-05 - mse: 151.3926 - val_loss: 2.0824e-05 - val_mse: 83.6641\n",
      "Epoch 2/50\n",
      "2412/2412 [==============================] - 2s 983us/step - loss: 3.3262e-05 - mse: 137.3437 - val_loss: 1.1114e-05 - val_mse: 44.5192\n",
      "Epoch 3/50\n",
      "2412/2412 [==============================] - 2s 986us/step - loss: 3.2425e-05 - mse: 131.6093 - val_loss: 1.4838e-05 - val_mse: 59.6247\n",
      "Epoch 4/50\n",
      "2412/2412 [==============================] - 3s 1ms/step - loss: 2.8107e-05 - mse: 113.5818 - val_loss: 1.4179e-05 - val_mse: 56.8507\n",
      "Epoch 5/50\n",
      "2412/2412 [==============================] - 3s 1ms/step - loss: 3.9665e-05 - mse: 160.3682 - val_loss: 1.2463e-05 - val_mse: 50.0090\n",
      "Epoch 6/50\n",
      "2412/2412 [==============================] - 3s 1ms/step - loss: 3.1697e-05 - mse: 128.2083 - val_loss: 1.1019e-05 - val_mse: 44.1309\n",
      "Epoch 7/50\n",
      "2412/2412 [==============================] - 3s 1ms/step - loss: 3.0773e-05 - mse: 124.2317 - val_loss: 1.1530e-05 - val_mse: 46.2052\n",
      "Epoch 8/50\n",
      "2412/2412 [==============================] - 2s 924us/step - loss: 2.4967e-05 - mse: 100.5462 - val_loss: 1.1131e-05 - val_mse: 44.5908\n",
      "Epoch 9/50\n",
      "2412/2412 [==============================] - 2s 981us/step - loss: 3.1627e-05 - mse: 128.1476 - val_loss: 2.0154e-05 - val_mse: 81.0103\n",
      "Epoch 10/50\n",
      "2412/2412 [==============================] - 2s 909us/step - loss: 3.6656e-05 - mse: 148.0672 - val_loss: 1.7081e-05 - val_mse: 68.5147\n",
      "Epoch 11/50\n",
      "2412/2412 [==============================] - 2s 843us/step - loss: 3.5497e-05 - mse: 144.8816 - val_loss: 1.6746e-05 - val_mse: 67.2469\n",
      "Epoch 12/50\n",
      "2412/2412 [==============================] - 2s 893us/step - loss: 5.3779e-05 - mse: 223.6600 - val_loss: 1.1198e-05 - val_mse: 44.8118\n",
      "Epoch 13/50\n",
      "2412/2412 [==============================] - 2s 912us/step - loss: 2.2936e-05 - mse: 92.2886 - val_loss: 1.1159e-05 - val_mse: 44.7041\n",
      "Epoch 14/50\n",
      "2412/2412 [==============================] - 2s 912us/step - loss: 3.4221e-05 - mse: 138.5891 - val_loss: 1.1624e-05 - val_mse: 46.4886\n",
      "Epoch 15/50\n",
      "2412/2412 [==============================] - 3s 1ms/step - loss: 3.3760e-05 - mse: 138.7347 - val_loss: 1.6307e-05 - val_mse: 65.4850\n",
      "Epoch 16/50\n",
      "2412/2412 [==============================] - 3s 1ms/step - loss: 2.9904e-05 - mse: 120.6824 - val_loss: 1.0922e-05 - val_mse: 43.7189\n",
      "Epoch 17/50\n",
      "2412/2412 [==============================] - 4s 2ms/step - loss: 2.5689e-05 - mse: 103.8269 - val_loss: 1.1352e-05 - val_mse: 45.4438\n",
      "Epoch 18/50\n",
      "2412/2412 [==============================] - 4s 2ms/step - loss: 2.8630e-05 - mse: 115.4807 - val_loss: 1.9334e-05 - val_mse: 78.0013\n",
      "Epoch 19/50\n",
      "2412/2412 [==============================] - 3s 1ms/step - loss: 2.8587e-05 - mse: 115.0108 - val_loss: 1.2341e-05 - val_mse: 49.5211\n",
      "Epoch 20/50\n",
      "2412/2412 [==============================] - 2s 1ms/step - loss: 2.8450e-05 - mse: 114.9589 - val_loss: 1.1064e-05 - val_mse: 44.3030\n",
      "Epoch 21/50\n",
      "2412/2412 [==============================] - 3s 1ms/step - loss: 3.0694e-05 - mse: 124.1392 - val_loss: 1.1069e-05 - val_mse: 44.3145\n",
      "Epoch 22/50\n",
      "2412/2412 [==============================] - 2s 876us/step - loss: 2.5567e-05 - mse: 103.1866 - val_loss: 4.6797e-05 - val_mse: 186.5528\n",
      "Epoch 23/50\n",
      "2412/2412 [==============================] - 2s 886us/step - loss: 3.0912e-05 - mse: 124.7592 - val_loss: 3.0775e-05 - val_mse: 121.9017\n",
      "Epoch 24/50\n",
      "2412/2412 [==============================] - 2s 965us/step - loss: 2.4456e-05 - mse: 98.4993 - val_loss: 1.3298e-05 - val_mse: 53.2150\n",
      "Epoch 25/50\n",
      "2412/2412 [==============================] - 2s 872us/step - loss: 2.7178e-05 - mse: 109.3404 - val_loss: 4.3293e-05 - val_mse: 171.5802\n",
      "Epoch 26/50\n",
      "2412/2412 [==============================] - 2s 890us/step - loss: 2.4558e-05 - mse: 98.8043 - val_loss: 1.9671e-05 - val_mse: 78.9228\n",
      "Epoch 27/50\n",
      "2412/2412 [==============================] - 2s 969us/step - loss: 3.1734e-05 - mse: 128.1221 - val_loss: 1.2846e-05 - val_mse: 51.5014\n",
      "Epoch 28/50\n",
      "2412/2412 [==============================] - 2s 845us/step - loss: 3.7685e-05 - mse: 153.6195 - val_loss: 1.0953e-05 - val_mse: 43.8290\n",
      "Epoch 29/50\n",
      "2412/2412 [==============================] - 2s 853us/step - loss: 2.9270e-05 - mse: 118.3633 - val_loss: 1.1554e-05 - val_mse: 46.2227\n",
      "Epoch 30/50\n",
      "2412/2412 [==============================] - 2s 950us/step - loss: 2.5277e-05 - mse: 102.1337 - val_loss: 1.1191e-05 - val_mse: 44.8050\n",
      "Epoch 31/50\n",
      "2412/2412 [==============================] - 2s 848us/step - loss: 4.4128e-05 - mse: 181.2108 - val_loss: 1.2258e-05 - val_mse: 49.0541\n",
      "Epoch 32/50\n",
      "2412/2412 [==============================] - 2s 859us/step - loss: 3.2777e-05 - mse: 135.3023 - val_loss: 1.2687e-05 - val_mse: 50.9151\n",
      "Epoch 33/50\n",
      "2412/2412 [==============================] - 2s 976us/step - loss: 3.1433e-05 - mse: 127.4391 - val_loss: 1.1268e-05 - val_mse: 45.1049\n",
      "Epoch 34/50\n",
      "2412/2412 [==============================] - 2s 841us/step - loss: 2.5493e-05 - mse: 102.8904 - val_loss: 2.1720e-05 - val_mse: 87.2780\n",
      "Epoch 35/50\n",
      "2412/2412 [==============================] - 2s 905us/step - loss: 3.5197e-05 - mse: 142.5113 - val_loss: 1.1455e-05 - val_mse: 45.8512\n",
      "Epoch 36/50\n",
      "2412/2412 [==============================] - 2s 1ms/step - loss: 2.5499e-05 - mse: 103.0054 - val_loss: 9.0796e-04 - val_mse: 3974.7505\n",
      "Epoch 37/50\n",
      "2412/2412 [==============================] - 2s 883us/step - loss: 2.6948e-05 - mse: 108.5445 - val_loss: 1.1854e-05 - val_mse: 47.5291\n",
      "Epoch 38/50\n",
      "2412/2412 [==============================] - 2s 873us/step - loss: 2.2217e-05 - mse: 89.3569 - val_loss: 1.2752e-05 - val_mse: 51.1805\n",
      "Epoch 39/50\n",
      "2412/2412 [==============================] - 3s 1ms/step - loss: 3.2532e-05 - mse: 131.0894 - val_loss: 1.3798e-05 - val_mse: 55.3474\n",
      "Epoch 40/50\n",
      "2412/2412 [==============================] - 2s 867us/step - loss: 2.4089e-05 - mse: 97.0976 - val_loss: 1.1568e-05 - val_mse: 46.3652\n",
      "Epoch 41/50\n",
      "2412/2412 [==============================] - 2s 913us/step - loss: 2.5088e-05 - mse: 101.1167 - val_loss: 1.1012e-05 - val_mse: 44.0789\n",
      "Epoch 42/50\n",
      "2412/2412 [==============================] - 2s 956us/step - loss: 3.3046e-05 - mse: 135.5371 - val_loss: 1.1788e-05 - val_mse: 47.2558\n",
      "Epoch 43/50\n",
      "2412/2412 [==============================] - 2s 894us/step - loss: 2.7853e-05 - mse: 112.2188 - val_loss: 1.1457e-05 - val_mse: 45.8471\n",
      "Epoch 44/50\n",
      "2412/2412 [==============================] - 2s 916us/step - loss: 3.4645e-05 - mse: 140.2420 - val_loss: 2.0170e-04 - val_mse: 803.2877\n",
      "Epoch 45/50\n",
      "2412/2412 [==============================] - 2s 1ms/step - loss: 2.3538e-05 - mse: 94.7776 - val_loss: 2.1182e-05 - val_mse: 85.1215\n",
      "Epoch 46/50\n",
      "2412/2412 [==============================] - 2s 889us/step - loss: 3.3337e-05 - mse: 135.1304 - val_loss: 1.5588e-05 - val_mse: 62.5985\n",
      "Epoch 47/50\n",
      "2412/2412 [==============================] - 2s 906us/step - loss: 2.5555e-05 - mse: 102.8590 - val_loss: 2.1102e-05 - val_mse: 84.6789\n",
      "Epoch 48/50\n",
      "2412/2412 [==============================] - 2s 929us/step - loss: 4.5775e-05 - mse: 188.1110 - val_loss: 1.1266e-05 - val_mse: 45.0665\n",
      "Epoch 49/50\n",
      "2412/2412 [==============================] - 2s 868us/step - loss: 2.5805e-05 - mse: 104.9630 - val_loss: 3.5216e-05 - val_mse: 141.8553\n",
      "Epoch 50/50\n",
      "2412/2412 [==============================] - 2s 929us/step - loss: 1.7504e-05 - mse: 70.2836 - val_loss: 1.4544e-05 - val_mse: 58.2273\n"
     ]
    }
   ],
   "source": [
    "model.compile(\"adam\", loss=\"mean_squared_logarithmic_error\", metrics=[\"mse\"])\n",
    "history_callback = model.fit(X_dev, y_dev, validation_data=(X_val, y_val), batch_size=256, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19296/19296 [==============================] - 10s 499us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.40443730324397764"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_preds = model.predict(X_dev)\n",
    "r2_score(dev_preds, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9992779686633b1a0c917c3f6317d760e57d78a77247aa4b25ad344de6939a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
